{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "cross-notebook",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "otherwise-borough",
   "metadata": {},
   "outputs": [],
   "source": [
    "from kfDataset2 import SeqDataset\n",
    "import config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "editorial-corpus",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.seq_len=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pointed-shield",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SeqDataset(seq_len=config.seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "objective-italy",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=config.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "satisfactory-theme",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = iter(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "distributed-waters",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x, y, input_lens) = i.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dirty-great",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 30, 24])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size() #batch_size, seq_len, num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "stainless-chinese",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 30, 24])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.size() #batch_size, seq_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "conscious-capture",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([9])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "developed-richardson",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.input_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "signal-anniversary",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 128\n",
    "num_layers = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "rough-masters",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = nn.LSTM(input_size=config.input_size, hidden_size=hidden_size,\n",
    "               num_layers=num_layers, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "adequate-mandate",
   "metadata": {},
   "outputs": [],
   "source": [
    "output, (hidden, cell) = lstm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "personalized-clone",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 30, 128])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.size() #batch_size, seq_len, hidden_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "manual-source",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 128])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden.size() #num_layers, batch_size, hidden_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "accessible-accident",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 128])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cell.size() #num_layers, batch_size, hidden_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "consecutive-occurrence",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.output_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "modified-calendar",
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_decoder = nn.LSTM(input_size=config.output_size, hidden_size=hidden_size, num_layers=num_layers, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fundamental-grant",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 30, 24])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "addressed-aviation",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_0 = y[:,0,:].unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "acknowledged-manual",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 24])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_0.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "approximate-assurance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_0.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "coordinate-tucson",
   "metadata": {},
   "outputs": [],
   "source": [
    "o,s = lstm_decoder(y_0, (hidden,cell))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "dense-warning",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 128])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "o.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "difficult-orchestra",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear = nn.Linear(hidden_size, config.output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "iraqi-decade",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = linear(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "welcome-electron",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 24])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "level-laptop",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeqEncoder(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, hidden_size, \n",
    "                 num_layers, dropout=0.5):\n",
    "        super(SeqEncoder, self).__init__()\n",
    "\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.lstm = nn.LSTM(self.input_size,\n",
    "                          self.hidden_size,\n",
    "                          num_layers=self.num_layers,\n",
    "                          batch_first=True,\n",
    "                           dropout=dropout)\n",
    "        #self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, input_x):\n",
    "       outputs, (hidden, cell) = self.lstm(input_x)\n",
    "       return hidden, cell\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "streaming-enemy",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeqDecoder(nn.Module):\n",
    "\n",
    "    def __init__(self, input_size, output_size, hidden_size, num_layers,dropout=0.5):\n",
    "        super(SeqDecoder, self).__init__()\n",
    "        self.output_size = output_size\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        self.lstm = nn.LSTM(self.input_size,\n",
    "                            self.hidden_size,\n",
    "                            num_layers=self.num_layers,\n",
    "                            batch_first=True,\n",
    "                            dropout=dropout\n",
    "                           )\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "        #self.softmax = nn.LogSoftmax(dim=1)\n",
    "        #self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "\n",
    "    def forward(self, x, hidden, cell):\n",
    "        x = x.unsqueeze(0)\n",
    "        output, (hidden, cell) = self.lstm(x, (hidden, cell))\n",
    "        prediction = self.out(output.squeeze(0))\n",
    "\n",
    "        return prediction, hidden, cell\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "weekly-westminster",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = SeqEncoder(config.input_size, hidden_size, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "acknowledged-stream",
   "metadata": {},
   "outputs": [],
   "source": [
    "h,c = encoder(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cooperative-minneapolis",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 128])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "informative-termination",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 128])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "structural-radar",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = SeqDecoder(config.output_size, config.output_size, hidden_size, num_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "olympic-charger",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 30, 24])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "deluxe-ready",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred, hh, cc = decoder(y[:, 0,:], h, c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "popular-thinking",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 24])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:, 0,:].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "hindu-tournament",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 24])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "phantom-teach",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 128])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hh.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "confident-tours",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 128])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cc.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "parliamentary-suspension",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, input_size, output_size, hidden_size, num_layers, dropout=0.5):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.encoder = SeqEncoder(input_size, hidden_size, num_layers, dropout=dropout)\n",
    "        self.decoder = SeqDecoder(output_size, output_size, hidden_size, num_layers, dropout=dropout)\n",
    "        \n",
    "        \n",
    "    def forward(self, x, y, seq_len, teacher_forcing_ratio = 0.5):\n",
    "        \n",
    "        #src = [src len, batch size]\n",
    "        #trg = [trg len, batch size]\n",
    "        #teacher_forcing_ratio is probability to use teacher forcing\n",
    "        #e.g. if teacher_forcing_ratio is 0.75 we use ground-truth inputs 75% of the time\n",
    "        \n",
    "        batch_size = x.shape[0]\n",
    "        \n",
    "        #tensor to store decoder outputs\n",
    "        outputs = torch.zeros(seq_len, batch_size, self.output_size)\n",
    "        \n",
    "        #last hidden state of the encoder is used as the initial hidden state of the decoder\n",
    "        hidden, cell = self.encoder(x)\n",
    "        \n",
    "        #first input to the decoder is the <sos> tokens\n",
    "        input = y[:,0,:]\n",
    "        \n",
    "        for t in range(1, seq_len):\n",
    "            \n",
    "            #insert input token embedding, previous hidden and previous cell states\n",
    "            #receive output tensor (predictions) and new hidden and cell states\n",
    "            predicted, hidden, cell = self.decoder(input, hidden, cell)\n",
    "            \n",
    "            #place predictions in a tensor holding predictions for each token\n",
    "            outputs[t] = predicted\n",
    "            \n",
    "            #decide if we are going to use teacher forcing or not\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            \n",
    "            #get the highest predicted token from our predictions\n",
    "            #top1 = output.argmax(1) \n",
    "            \n",
    "            #if teacher forcing, use actual next token as next input\n",
    "            #if not, use predicted token\n",
    "            input = y[:,t,:] if teacher_force else predicted\n",
    "        \n",
    "        return outputs\n",
    "    \n",
    "    def create_start_action(self):\n",
    "        action = torch.zeros((1, self.output_size))\n",
    "        action[config.seq_types.index('start')] = 1\n",
    "        return action\n",
    "\n",
    "    def predict(self, x, max_seq_len):\n",
    "        \n",
    "        batch_size = x.shape[0]\n",
    "        \n",
    "        #outputs = torch.zeros(max_seq_len, batch_size, self.output_size)\n",
    "        \n",
    "        hidden, cell = self.encoder(x)\n",
    "        \n",
    "        predicted_seq_types = []\n",
    "        \n",
    "        input = self.create_start_action()\n",
    "        \n",
    "        for t in range(1, max_seq_len):\n",
    "            predicted, hidden, cell = self.decoder(input, hidden, cell)\n",
    "            #outputs[t] = predicted\n",
    "            p = nn.functional.softmax(predicted[0], dim=0)\n",
    "            pred_action = config.seq_types[p.argmax().item()]\n",
    "            predicted_seq_types.append(pred_action)\n",
    "            if pred_action == 'end':\n",
    "                break\n",
    "        return predicted_seq_types\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "foreign-merchandise",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq2seq = Seq2Seq(config.input_size, config.output_size, hidden_size, num_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "desperate-investigator",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_lens.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "surprising-prevention",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = seq2seq(x, y, input_lens.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "binary-fiber",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([9, 1, 24])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.size() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "accurate-literature",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 30, 24])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "limited-initial",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0,  1,  2,  3,  4,  5,  6,  7, 23,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0].argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "personal-butler",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 30, 24])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "herbal-latest",
   "metadata": {},
   "outputs": [],
   "source": [
    "x0 = x[:, :9, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "shaped-assets",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = seq2seq(x, y, input_lens.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "suspended-equity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 24])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[1:, 0, :].size() # seq_len - start, #output_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "spectacular-alberta",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 30, 24])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "classified-detector",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_target = y[0, 1:input_lens.item()].argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "frank-frank",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0401, 0.0403, 0.0422, 0.0404, 0.0436, 0.0422, 0.0373, 0.0437, 0.0385,\n",
       "        0.0431, 0.0430, 0.0439, 0.0409, 0.0441, 0.0439, 0.0432, 0.0397, 0.0399,\n",
       "        0.0380, 0.0433, 0.0424, 0.0450, 0.0381, 0.0431],\n",
       "       grad_fn=<SoftmaxBackward>)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = nn.functional.softmax(pred[0], dim=0)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "neither-tuning",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'edit_object'"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config.seq_types[p.argmax().item()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "finished-commonwealth",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs):\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(seq2seq.parameters(), lr= config.lr)\n",
    "    seq2seq.train()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        #TODO for each x, get correct seq_len\n",
    "        output = seq2seq(x, y, input_lens.item())\n",
    "        \n",
    "        y_pred = output[1:, 0, :]\n",
    "        y_target = y[0, 1:input_lens.item()].argmax(axis=1)\n",
    "        \n",
    "        loss = loss_fn(y_pred, y_target)\n",
    "        loss.backward()\n",
    "        \n",
    "        #torch.nn.utils.clip_grad_norm(seq2seq.parameters(), clip)\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    return epoch_loss/epochs\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "fixed-robert",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.004961857158923522"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "mighty-public",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "sensitive-table",
   "metadata": {},
   "outputs": [],
   "source": [
    "start = torch.zeros((1, config.output_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "major-composer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 24])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occupational-voluntary",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(x):\n",
    "    output = seq2seq()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "rubber-float",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['start',\n",
       " 'get_note',\n",
       " 'get_links_from',\n",
       " 'record_note_read',\n",
       " 'get_links_from_contrib',\n",
       " 'edit_note',\n",
       " 'notify_comm',\n",
       " 'record_note_edited',\n",
       " 'get_object',\n",
       " 'get_groups',\n",
       " 'get_links_to_note',\n",
       " 'search',\n",
       " 'post_scaffold',\n",
       " 'get_community',\n",
       " 'get_note_records',\n",
       " 'get_author',\n",
       " 'delete_scaffold',\n",
       " 'new_note',\n",
       " 'post_link_view_note',\n",
       " 'new_attachment',\n",
       " 'upload_attachment',\n",
       " 'edit_object',\n",
       " 'post_link',\n",
       " 'end']"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "governmental-console",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
